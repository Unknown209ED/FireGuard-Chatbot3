
# FireGuard AI-Powered Chatbot with Content Moderation ðŸ”¥

# List of restricted words (local filtering)
restricted_words = ["suicide", "kill", "self-harm", "nsfw", "nude"]

def analyze_content(text):
    """Analyzes text for harmful/inappropriate content"""
    words = text.lower().split()
    flagged_words = [word for word in words if word in restricted_words]
    return flagged_words

def manual_review(flagged_words):
    """Allows admin to review and approve new restrictions"""
    global restricted_words
    print("Flagged words:", flagged_words)
    confirm = input("Do you approve adding these to restrictions? (yes/no) ")
    if confirm.lower() == "yes":
        restricted_words.extend(flagged_words)
        restricted_words = list(set(restricted_words))  # Remove duplicates
        print("Updated restricted words:", restricted_words)
    else:
        print("No changes made.")

import requests

def ai_moderation(text):
    """Uses OpenAI's Moderation API for advanced filtering"""
    API_KEY = "YOUR_OPENAI_API_KEY"  # Replace with your actual API key
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    response = requests.post("https://api.openai.com/v1/moderations", headers=headers, json={"input": text})
    data = response.json()
    return data["results"][0]["flagged"]

if __name__ == "__main__":
    user_text = input("Enter text to scan: ")
    flagged_words = analyze_content(user_text)
    ai_flagged = ai_moderation(user_text)
    
    if flagged_words or ai_flagged:
        print("ðŸš¨ Inappropriate content detected!")
        if flagged_words:
            print("Flagged words:", flagged_words)
        manual_review(flagged_words)
    else:
        print("âœ… Your message is safe!")
